{
  
    
        "post0": {
            "title": "Install Python with Conda",
            "content": "Personal Python Preferences . note: These are recommendations, not hard and fast rules. There are trade-offs in every decision in software. . While your set up is largely up to personal preference, some factors to consider are: . How many different computers you use (will your configuration transfer easily?) | How many different OS&#39;s you use (will your configuration work between Windows / Linux?) | How many projects or versions of python / python packages do you need to use | How invested are you in learning the command line (would GUI make your life much less stressful?) | . The following set up has worked well for me doing working with multiple python versions on both Windows and Ubuntu/Debian systems. . Installing . Download and Install Python Conda . . Use Miniconda, the little sibling of Anaconda. It manages downloading and using different python versions and has some unique &quot;virtual environment&quot; features that are especially nice in data science work. . For the most up to date information (i.e. if the following doesn&#39;t work), see the official guide and click the link for your OS | Browser / GUI method: Download the installer for Python 3.9 for your computer&#39;s OS (or 3.10 if available). note most Windows computers are 64-bit these days, if you&#39;re unsure just double check | . | Run the file that was downloaded (probably in your ~/Downloads folder) Ask it to add python to your account&#39;s PATH variable. | Installing just for yourself should be fine for most users | . | . | Command line method: . note right click links on website to get specific base version of Python (latest is fine in most cases) | Windows Powershell . # Download the installer exe curl -uri https://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe -outfile MinicondaInstaller.exe # Install &amp; . MinicondaInstaller.exe /AddToPath=0 /InstallationType=JustMe /RegisterPython=0 /S /D=%UserProfile% Miniconda3 . | Linux bash (MacOS needs different download link) . # Download curl -url https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh --output MinicondaInstaller.sh # Install bash MinicondaInstaller.sh . | . | . | . Initialize Conda Base Environment . note This glosses over what virtual environments actually are entirely. This is intended to keep the document short. In essence they are folders that each hold a specific version of python and specific versions of python packages. . 2 Goals: . Python can make new virtual environments for different projects | Allows your code editor to utilize tools like black and flake8 to automatically format your code, show you what variables and functions you can use, and catch simple errors and tpyos before you run your code | . Conda Init . After Installing Miniconda . On windows open Anaconda Powershell Prompt on Windows, terminal for linux Enter conda init powershell then close and move on to the next step note if Windows fails to do the initialization and instead makes a pop-up about &quot;Folder Security&quot;, click the pop up then take action to allow the changes. You&#39;ll need to re-run the conda init command. | . | . | open up a new terminal note if you installed via command line method, you may need to close your current terminal and reopen | If you see (base) on the left of your current line try running the following commandpython --version . | If you don&#39;t see (base), try running the following command. Then open a new terminal window and try something like the python --version command again.conda init . | . | . Python Base Environment . Install some packages in the (base) conda virtual environment that are useful for code formatting and testing: . # Windows Powershell # Download the requirements file (base)$&gt; curl -uri https://gist.githubusercontent.com/gerardrbentley/b4fd6bdeb9167462cf990160ec246512/raw/e7194b303bb59e518e5d28c65e916cf3ebf1032a/base.requirements.txt -outfile base.requirements.txt # Install (base)$&gt; python -m pip install -r base.requirements.txt # Unix # Download the requirements file (base)$&gt; curl -url https://gist.githubusercontent.com/gerardrbentley/b4fd6bdeb9167462cf990160ec246512/raw/e7194b303bb59e518e5d28c65e916cf3ebf1032a/base.requirements.txt --output base.requirements.txt # Install (base)$&gt; python -m pip install -r base.requirements.txt . | . txt # formatter black # % testing coverage coverage # linter + static checker flake8 # interact with jupyter notebooks ipykernel # sort imports in a consistent fashion isort # let flake8 nag you about object naming pep8-naming # test your code pytest # make pytest and coverage play nicely pytest-cov . VS Code Text Editor Setup . VS Code is a very popular code editor with powerful features, active community extensions, and gets useful updates frequently. It&#39;s by no means the only way to program with Python, but it&#39;s one of the most beginner friendly ways to work on a variety of projects. . Set up test project . Make a folder called something like test_python and a file inside it called first_script.py . sh mkdir test_python cd test_python touch first_script.py . Download and Install VS Code . Download from your OS link | Install with downloaded file | Open VS Code for the first time | If it won&#39;t work or can&#39;t open, try reading their getting started guides | . Open your test project in VS Code . File -&gt; Open Folder Select the test_python folder | If a &quot;Trust this workspace&quot; message pops up, hit agree / trust | Open the first_script.py file Write something like print(&#39;Hello There&#39;) and save the file | . | . | Go back to your terminal and run python first_script.py | . Install Extensions for Python . In VS Code, open the extensions menu on the left (or with ctrl+shift+x) . Search for and install the following: Python (Microsoft) | . | Reload the window now (close and reopen VS Code) or install some more of the things below then reload (all are optional) | . Some other nice extensions (not necessary off the bat) . Python Specific Python Docstring Generator (Nils Werner) | Even Better TOML (tamasfe) | . | General VS Code indent-rainbow (oderwat): Visualize deeply indented blocks more easily | GitLens (Eric Amodio): Quickly check git history of files, branches, lines, etc. | . | Various File Types Markdown TOC (AlanWalk) | markdownlint (David Anson) | XML (Red Hat) | SQL Formatter (adpyke) | . | . Bonus: For Emacs users, &quot;Awesome Emacs Keymap&quot; will get you most of the way to familiar text editing keybindings . VS Code Set Python Env and Formatter . Recommended settings in VS Code . Type ctrl+shift+p then type &quot;settings json&quot; and select the entry, add these key-value pairs to file Edit the CHANGEME:USERNAME with your Windows user. (On Ubuntu based systems use /home/username/miniconda3/bin/python, similar for other Unix systems but with relevant user home directory) | . | . note: you can instead use ctrl+shift+p and search &quot;settings ui&quot; (or use ctrl+,) and then search for each of the keynames below to explore what other settings you might like to try. . { &quot;python.pythonPath&quot;: &quot;C: Users CHANGEME:USERNAME miniconda3 python.exe&quot;, &quot;files.autoSave&quot;: &quot;onFocusChange&quot;, &quot;editor.wordWrap&quot;: &quot;on&quot;, &quot;editor.wordWrapColumn&quot;: 88, &quot;jupyter.alwaysTrustNotebooks&quot;: true, &quot;python.linting.flake8Enabled&quot;: true, &quot;python.linting.flake8Args&quot;: [ &quot;--max-line-length=88&quot; ], &quot;python.analysis.typeCheckingMode&quot;: &quot;basic&quot;, &quot;workbench.editorAssociations&quot;: [ { &quot;viewType&quot;: &quot;jupyter.notebook.ipynb&quot;, &quot;filenamePattern&quot;: &quot;*.ipynb&quot; } ], &quot;python.linting.pylintEnabled&quot;: false, &quot;python.formatting.provider&quot;: &quot;black&quot;, &quot;python.linting.ignorePatterns&quot;: [ &quot;.vscode/*.py&quot;, &quot;**/site-packages/**/*.py&quot;, &quot;venv/*.py&quot; ], &quot;python.testing.pytestEnabled&quot;: true, &quot;python.venvPath&quot;: &quot;${workspaceFolder}&quot; } . Get on to Getting Things Done . That&#39;s the bare-bones Python setup. . Feel free to try out / research the following (Python related): . Typing error-filled python code and see how flake8 warns you | Start your .py document with # %% to make it a VS Code &quot;Python Interactive&quot; document (really awesome way to experiment with code blocks and debug small chunks) | Use alt+shift+f or ctrl+shift+p and search &#39;Format Document&#39; to format python according to black standard | Text Editing and Searching Guide including stuff like using multiple cursors, search and replace over multiple files, auto save (which is included in my json settings above) | Make a new virtual environment for your project with python -m venv venv or look into using conda to manage your environments | Look into VS Code&#39;s live code sharing and git integrations to collaborate better | . Or expand your environment by setting up a few more tools (tangential to Python): . Look into Emmet the auto completer for html files built into VS Code | Install Node if you&#39;re going to be doing some web development or otherwise need npm | Install Docker if you want to explore modern container based deployment | Find some good Python Reading (Ok one more Python recommendation; some of these are available for low-to-no cost from the authors) | .",
            "url": "https://tech.gerardbentley.com/python/beginner/2022/01/29/install-python.html",
            "relUrl": "/python/beginner/2022/01/29/install-python.html",
            "date": " • Jan 29, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Scanning URLs from Images",
            "content": "Scanning QR codes for humans: URLs . The idea for this popped up when talking to my mom about how QR codes work. The simple usecase for QR codes is the same as a URL: get the user to a certain website. . So why can&#39;t we just scan a real URL with our cameras...? (spoiler: many modern android and ios devices can, but that&#39;s a short end to the story) . I&#39;m all for QR codes being used for more things, but URLs aren&#39;t going away any time soon for a few reasons: . Not everybody knows how to make a QR code (hint: write click on a page in Chrome or use the python-qrcode library) | URLs often contain the company name so people can remember them (qr codes can contain logos in some cases) | URLs are a single line (most of the time) rather than taking up a whole square of printing / advertising space | . I also wanted to give a live Streamlit app a shot after using it for some AI demos with students. So was born the Streamlit URL Scanner! . In this notebook I&#39;ll breakdown the basic mechanisms behind the app, see the full source code on github . Python Dependencies . There are 3 goals for this app: . Allow user to upload images containing URLs to the web app | Run high-accuracy Optical Character Recognition (OCR) on the uploaded image | Provide any URLs from the extracted text to the user for easy clicking | . I went with the libraries that I thought would give the fastest and most successful development experience. . Python Web App . streamlit: Python rapid development web app framework Provides a file upload component out of the box with st.file_uploader | Simple Cloud deployment with secure secrets for OCR component | . | . Contenders . fastapi: Providing a route to OCR component as a service Asynchronous by default is nice for handling distributed transactions to OCR task | . | django: Overbaked for usecase This is a proof of concept tool, not a full-stack user-oriented website | . | flask / bottle: Have ways of being asynchronous, but synchronous by default | . | . All of these other options would require a frontend app or integrating some JS library or other index.html + JS + CSS combination . OCR . AWS Rekognition: Trained for text detection on real world images Limited to 100 words detected | Accessed with the boto3 library | . | . Contenders . AWS Textract: More tuned for documents than real world | Tesseract: Still a good OCR, but also focused on documents Can be self-hosted, not paid per transaction | . | . URL Extraction . urlextract: I didn&#39;t want to write a regex for URLs when there&#39;s a small library without any known issues | . Glue Code . PIL / Pillow: Python Imaging Library for handling user uploaded images and resizing if needed | pydantic: Typed Settings management with loading from CLI, Environment, Secrets | . import io import json import boto3 import streamlit as st from PIL import Image, ImageDraw, ImageOps from pydantic import BaseSettings from urlextract import URLExtract . OCR + Extractor Setup . Pydantic&#39;s BaseSettings Class allows us to read in settings for connecting to AWS account. This can be used with Docker secrets, but this app is deployed to Streamlit cloud. . boto3 lets us establish a client to the Rekognition service. . URL Extract requires some initialization to recognize all domain names. . class Settings(BaseSettings): &quot;&quot;&quot;Handles fetching configuration from environment variables and secrets. Type-hinting for config as a bonus&quot;&quot;&quot; aws_access_key_id: str aws_secret_access_key: str aws_region: str settings = Settings() rekog_client = boto3.client( &quot;rekognition&quot;, region_name=settings.aws_region, aws_access_key_id=settings.aws_access_key_id, aws_secret_access_key=settings.aws_secret_access_key, ) extractor = URLExtract() . 2022-01-27 18:44:24.510 INFO filelock: Lock 139763555315184 acquired on /home/gar/miniconda3/lib/python3.8/site-packages/urlextract/data/tlds-alpha-by-domain.txt.lock 2022-01-27 18:44:24.555 INFO filelock: Lock 139763555315184 released on /home/gar/miniconda3/lib/python3.8/site-packages/urlextract/data/tlds-alpha-by-domain.txt.lock . Detecting Text in an Image . AWS Rekognition can receive either a path to an S3 object or raw image bytes. For this app I went with passing just the image bytes, so a helper function to compress larger images was needed. We&#39;ll ignore the streamlit specific alert message that this is happening for this demo. (The S3 version isn&#39;t much more complicated, and is beneficial for more general OCR apps) . Another small helper for passing the correct parameters to boto3 will wrap up this section. . Pillow will do our image handling in the app, so we&#39;ll use it for showing a demo detection in the following code cells . def compress_pil_image(image: Image, limit=(5 * (2 ** 20))) -&gt; bytes: &quot;&quot;&quot;Takes a Pillow image and returns byte values of the image saved as png. Reduces dimensions of image if it is larger than provided limit. Args: image (Image): Image to get the bytes for limit (int, optional): Maximum number of bytes. Defaults to 5mb (5 * (2 ** 20)). Returns: bytes: image saved as PNG bytes object &quot;&quot;&quot; image_bytes = io.BytesIO() image.save(image_bytes, &quot;PNG&quot;) output = image_bytes.getvalue() limit_to_bytes_ratio = limit / len(output) if limit_to_bytes_ratio &gt;= 1.0: return output else: # st.warning(f&quot;Resizing by ratio: {limit_to_bytes_ratio}&quot;) width, height = image.size new_width = int(width * limit_to_bytes_ratio) new_height = int(height * limit_to_bytes_ratio) new_image = image.resize((new_width, new_height), Image.ANTIALIAS) return compress_pil_image(new_image, limit) def rekog_detect_by_bytes(image_bytes: bytes) -&gt; dict: &quot;&quot;&quot;Takes an array of bytes representing jpg / png image. Tries to return response from AWS Rekognition detect_text API on the image bytes See docs for more: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html#Rekognition.Client.detect_text # noqa: E501 Args: image_bytes (bytes): Image to run detection on (less than 5 mb) Returns: dict: List of text detections, geometry of the detections, and metadata &quot;&quot;&quot; response = rekog_client.detect_text(Image={&quot;Bytes&quot;: image_bytes}) return response . demo_image = Image.open(&#39;test_images/sample_urls.jpg&#39;) demo_image . image_bytes = compress_pil_image(demo_image) rekognotion_response = rekog_detect_by_bytes(image_bytes) rekognotion_response . {&#39;TextDetections&#39;: [{&#39;DetectedText&#39;: &#39;Lorem ipsum...&#39;, &#39;Type&#39;: &#39;LINE&#39;, &#39;Id&#39;: 0, &#39;Confidence&#39;: 83.6632080078125, &#39;Geometry&#39;: {&#39;BoundingBox&#39;: {&#39;Width&#39;: 0.198333278298378, &#39;Height&#39;: 0.05164804682135582, &#39;Left&#39;: 0.4017779529094696, &#39;Top&#39;: 0.3004961609840393}, &#39;Polygon&#39;: [{&#39;X&#39;: 0.4021288752555847, &#39;Y&#39;: 0.3004961609840393}, {&#39;X&#39;: 0.6001112461090088, &#39;Y&#39;: 0.3018783628940582}, {&#39;X&#39;: 0.5997602939605713, &#39;Y&#39;: 0.3521442115306854}, {&#39;X&#39;: 0.4017779529094696, &#39;Y&#39;: 0.3507620096206665}]}}, {&#39;DetectedText&#39;: &#39;google.com&#39;, &#39;Type&#39;: &#39;LINE&#39;, &#39;Id&#39;: 1, &#39;Confidence&#39;: 99.61248779296875, &#39;Geometry&#39;: {&#39;BoundingBox&#39;: {&#39;Width&#39;: 0.142822265625, &#39;Height&#39;: 0.0458984375, &#39;Left&#39;: 0.428466796875, &#39;Top&#39;: 0.3544921875}, &#39;Polygon&#39;: [{&#39;X&#39;: 0.428466796875, &#39;Y&#39;: 0.3544921875}, {&#39;X&#39;: 0.5712890625, &#39;Y&#39;: 0.3544921875}, {&#39;X&#39;: 0.5712890625, &#39;Y&#39;: 0.400390625}, {&#39;X&#39;: 0.428466796875, &#39;Y&#39;: 0.400390625}]}}, {&#39;DetectedText&#39;: &#39;https://streamlit.io/&#39;, &#39;Type&#39;: &#39;LINE&#39;, &#39;Id&#39;: 2, &#39;Confidence&#39;: 97.68013763427734, &#39;Geometry&#39;: {&#39;BoundingBox&#39;: {&#39;Width&#39;: 0.2527962923049927, &#39;Height&#39;: 0.051752522587776184, &#39;Left&#39;: 0.37402498722076416, &#39;Top&#39;: 0.45518985390663147}, &#39;Polygon&#39;: [{&#39;X&#39;: 0.37402498722076416, &#39;Y&#39;: 0.455630898475647}, {&#39;X&#39;: 0.6267316937446594, &#39;Y&#39;: 0.45518985390663147}, {&#39;X&#39;: 0.6268212795257568, &#39;Y&#39;: 0.506501317024231}, {&#39;X&#39;: 0.3741145431995392, &#39;Y&#39;: 0.5069423913955688}]}}, {&#39;DetectedText&#39;: &#39;Lorem&#39;, &#39;Type&#39;: &#39;WORD&#39;, &#39;Id&#39;: 3, &#39;ParentId&#39;: 0, &#39;Confidence&#39;: 99.94923400878906, &#39;Geometry&#39;: {&#39;BoundingBox&#39;: {&#39;Width&#39;: 0.07525634765625, &#39;Height&#39;: 0.0341796875, &#39;Left&#39;: 0.402099609375, &#39;Top&#39;: 0.3046875}, &#39;Polygon&#39;: [{&#39;X&#39;: 0.402099609375, &#39;Y&#39;: 0.3046875}, {&#39;X&#39;: 0.47735595703125, &#39;Y&#39;: 0.3046875}, {&#39;X&#39;: 0.47735595703125, &#39;Y&#39;: 0.3388671875}, {&#39;X&#39;: 0.402099609375, &#39;Y&#39;: 0.3388671875}]}}, {&#39;DetectedText&#39;: &#39;ipsum...&#39;, &#39;Type&#39;: &#39;WORD&#39;, &#39;Id&#39;: 4, &#39;ParentId&#39;: 0, &#39;Confidence&#39;: 67.37718200683594, &#39;Geometry&#39;: {&#39;BoundingBox&#39;: {&#39;Width&#39;: 0.11253990232944489, &#39;Height&#39;: 0.05104871839284897, &#39;Left&#39;: 0.48755744099617004, &#39;Top&#39;: 0.30109521746635437}, &#39;Polygon&#39;: [{&#39;X&#39;: 0.4879346489906311, &#39;Y&#39;: 0.30109521746635437}, {&#39;X&#39;: 0.6000973582267761, &#39;Y&#39;: 0.30386465787887573}, {&#39;X&#39;: 0.5997201800346375, &#39;Y&#39;: 0.35214391350746155}, {&#39;X&#39;: 0.48755744099617004, &#39;Y&#39;: 0.3493745028972626}]}}, {&#39;DetectedText&#39;: &#39;google.com&#39;, &#39;Type&#39;: &#39;WORD&#39;, &#39;Id&#39;: 5, &#39;ParentId&#39;: 1, &#39;Confidence&#39;: 99.61248779296875, &#39;Geometry&#39;: {&#39;BoundingBox&#39;: {&#39;Width&#39;: 0.142822265625, &#39;Height&#39;: 0.0458984375, &#39;Left&#39;: 0.428466796875, &#39;Top&#39;: 0.3544921875}, &#39;Polygon&#39;: [{&#39;X&#39;: 0.428466796875, &#39;Y&#39;: 0.3544921875}, {&#39;X&#39;: 0.5712890625, &#39;Y&#39;: 0.3544921875}, {&#39;X&#39;: 0.5712890625, &#39;Y&#39;: 0.400390625}, {&#39;X&#39;: 0.428466796875, &#39;Y&#39;: 0.400390625}]}}, {&#39;DetectedText&#39;: &#39;https://streamlit.io/&#39;, &#39;Type&#39;: &#39;WORD&#39;, &#39;Id&#39;: 6, &#39;ParentId&#39;: 2, &#39;Confidence&#39;: 97.68013763427734, &#39;Geometry&#39;: {&#39;BoundingBox&#39;: {&#39;Width&#39;: 0.2527649700641632, &#39;Height&#39;: 0.051752522587776184, &#39;Left&#39;: 0.3740406334400177, &#39;Top&#39;: 0.45518985390663147}, &#39;Polygon&#39;: [{&#39;X&#39;: 0.3740406334400177, &#39;Y&#39;: 0.4563566744327545}, {&#39;X&#39;: 0.6267316937446594, &#39;Y&#39;: 0.45518985390663147}, {&#39;X&#39;: 0.6268056035041809, &#39;Y&#39;: 0.5057755708694458}, {&#39;X&#39;: 0.3741145431995392, &#39;Y&#39;: 0.5069423913955688}]}}], &#39;TextModelVersion&#39;: &#39;3.0&#39;, &#39;ResponseMetadata&#39;: {&#39;RequestId&#39;: &#39;6ee34f23-945f-45ea-9fe4-439580da7ff2&#39;, &#39;HTTPStatusCode&#39;: 200, &#39;HTTPHeaders&#39;: {&#39;x-amzn-requestid&#39;: &#39;6ee34f23-945f-45ea-9fe4-439580da7ff2&#39;, &#39;content-type&#39;: &#39;application/x-amz-json-1.1&#39;, &#39;content-length&#39;: &#39;2883&#39;, &#39;date&#39;: &#39;Fri, 28 Jan 2022 02:56:30 GMT&#39;}, &#39;RetryAttempts&#39;: 0}} . Extracting URLs from Text . If you&#39;re not familiar with APIs or bounding boxes the above output might be a bit of a mess. That&#39;s alright, we&#39;re here to work through it. . Rekognition&#39;s text detection returns a List of &quot;Text Detection&quot; records. Each of these &quot;Text Detections&quot; has a few features, but the most important to our purpose is &quot;Detected Text.&quot; . If we&#39;re really just interested in the text, we can use a list comprehension to get the detections and pass them to the URL extractor . detected_text = [detection[&#39;DetectedText&#39;] for detection in rekognotion_response[&#39;TextDetections&#39;] if detection[&quot;Type&quot;] == &quot;LINE&quot;] extracted_urls = extractor.find_urls(&quot; &quot;.join(detected_text)) extracted_urls . [&#39;google.com&#39;, &#39;https://streamlit.io/&#39;] . Streamlit aspect . Streamlit provides the frontend components for uploading and viewing images and links. (And giving a semblance of user experience) . It&#39;s hard to demo these aspects in a notebook, but here are the streamlit snippets and use cases in the app. . # Header and Description st.title(&quot;URL Scan :computer:&quot;) st.header( &quot;Never type a URL from real life again! &quot; &quot;Take a picture with a URL in it and we&#39;ll scan any links so you can click them!&quot; ) st.subheader(&quot;(Or upload an image you already have on your device)&quot;) # Retrieve image from camera or upload camera_bytes = st.camera_input(&quot;Take a picture&quot;) uploaded_bytes = st.file_uploader( &quot;Upload an image&quot;, type=[&quot;png&quot;, &quot;jpg&quot;, &quot;jpeg&quot;], ) # Context manager to give better loading experience with st.spinner(&quot;Loading Image Bytes&quot;): # Compress pil image pass # Provide visual alerts to the user st.success( f&quot;Found {len(extracted_urls)} URLs!&quot; ) # Allow downloading the detected text / urls st.download_button( label=&quot;Download extracted url list&quot;, data=&#39; n&#39;.join(extracted_urls), file_name=&quot;extracted_urls.txt&quot;, mime=&quot;text&quot;, ) # Display the raw and detected images st.image( demo_image, use_column_width=True, ) . Testing and deployment . Docker is used to help smooth environments between windows / linux / mac. Docker-compose is used to open up to future extensions with other backend apps. . Linting, Static Checking, and Testing are handled locally before deployment. . E2E testing consists of Selenium visual baseline testing against locally deployed app in docker-compose . Deployment would be straightforward with docker-compose, but Streamlit cloud provides plenty of resources for this use case. Not having to write a CI/CD pipeline is fine by me. . Downsides are the need to deploy secrets manually to streamlit and it requires setting up a seperate app deployment if a staging / UAT environment is desired. . BONUS: Painting detections . The url extraction code used above isn&#39;t the same process as used in the app. I think the bounding box aspect of text detection is engaging for users to understand the OCR component, so I include a copy of their image with the bounding boxes painted on. . We get all of the location data in the &quot;Text Detections&quot; from Rekognition, but we have to do a bit of conversion from their format to draw them with Pillow&#39;s ImageDraw. In this case we&#39;re converting from a format that provides the Width, Height, Left-side X coordinate, and Top-side Y coordinate in percentage of the image size. . Our goal is to use some arithmetic to get the (X,Y) coordinates of the top-left corner of our bounding box and the bottom-right corner in pixels. (If you haven&#39;t worked with bounding boxes, there&#39;s even more possible formats...) . image_w, image_h = demo_image.size painted_image = demo_image.copy() canvas = ImageDraw.Draw(painted_image) for detection in rekognotion_response[&quot;TextDetections&quot;]: if detection[&quot;Type&quot;] == &quot;LINE&quot;: text = detection[&quot;DetectedText&quot;] aws_bbox = detection[&quot;Geometry&quot;][&quot;BoundingBox&quot;] top_left_x = aws_bbox[&quot;Left&quot;] * image_w top_left_y = aws_bbox[&quot;Top&quot;] * image_h box_width = aws_bbox[&quot;Width&quot;] * image_w box_height = aws_bbox[&quot;Height&quot;] * image_h bot_right_x = top_left_x + box_width bot_right_y = top_left_y + box_height canvas.rectangle( (top_left_x, top_left_y, bot_right_x, bot_right_y), outline=&quot;Red&quot;, width=3, ) painted_image .",
            "url": "https://tech.gerardbentley.com/streamlit/python/aws/2022/01/24/streamlit-url-scan.html",
            "relUrl": "/streamlit/python/aws/2022/01/24/streamlit-url-scan.html",
            "date": " • Jan 24, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "The Terminal (/ Shell / Command Line / Console...)",
            "content": "What’s a Terminal . The Terminal, which you might also hear called shell, console, or command line (with a fair bit of nuance) is a program that lets you enter commands for the computer to run. In different computers the program will vary (Terminal, Powershell, bash, etc.), but the idea of interacting with the computer using text commands one line at a time is present in all of them. . Why Keyboard Over Mouse? . So the Terminal lets you access apps and files and execute programs without using a mouse or other windows, but why would you want to abandon your mouse? All of the work we do in a Terminal is both plain text and can be automated much more easily than mouse movements and clicks. . Using a shell also usually gives you access to the Kernel of your OS, the software in control of basically all your applications, so you can take back your technological freedom. . Finally, Graphical (GUI) interfaces aren’t available for all programs, especially a lot of the older software. It’s generally easier to develop a program that takes a few Command Line arguments than a full blown GUI Application. . 3 Navigation Commands . When you open Terminal.app (on many linux distros use super+spacebar, on mac you use command+spacebar then search Terminal) all you get is a blank command line prompt, probably ending with $ . The terminal works like a filesystem/Finder window in that you need to navigate ‘up’ and ‘down’ into different folders to find particular files. When you open a new Terminal it is most likely located at your account’s Home folder (also referred to as ~). . NOTE: On Mac the ~ can be replaced with /Users/YOUR-USERNAME/ for an “absolute” path (absolute vs relative explanation). Ubuntu based distros ~ == /home/YOUR-USERNAME/. And Windows is different… ~ == C: Users YOUR-USERNAME. For reference, your Desktop folder is located at ~/Desktop, your Documents at ~/Documents . Now for the 3 Basic commands that will help you navigate around (type these in the command line and hit enter): . pwd . Print Working Directory: Tells you where in the filesystem the command line is currently pointed. On a fresh Terminal window it should show /Users/YOUR-USERNAME/ . ls . List: Lists out all the files and directories in the current directory you’re pointed at. Also helps you know where in the filesystem you are and what files you have easy access to. . cd . Change Directory: Actually moves where the command line is pointed to a different directory / folder. . The common uses of cd and ls: . Go to your project folder . On my personal computer I try to keep all my coding projects under a folder called research (in their own individual folders) which is in my Home folder (~/research or /Users/Gerard/research) . So to get to my project I open terminal and enter . cd research/my-project-folder . NOTE: This works because the Terminal is already pointed at my ~/ directory and research is in that directory. You can use ls to see if research is present in your Home directory . If you don’t remember the project-folder name you can do the following . cd research ls . This will show you all the files and folders in research, then you can cd directly into it without the research/ part . cd project-folder-i-remember-now . Go back one or more directories . Just like ~/ is a shorthand symbol for “Home Directory”, ./ is a symbol for the current working directory (pwd) . By this I mean that . represents the current working directory, where the terminal command line is pointed. . So the same command from before works the same like this (from a fresh Terminal located at ~/) . cd ./research/my-project-folder . After executing that command, pwd will tell you the Terminal is at /Users/Gerard/research/my-project-folder, which we want because we just cdd into that directory . If we wanted to switch projects (to a different folder in research), we need to go ‘up’ a folder. To do this we use .. to represent the folder ‘above’ the current folder . cd .. . This brings us back to research, so pwd will say /Users/Gerard/research/ . Now we can cd into a different folder . cd my-other-project-folder . If we wanted to switch to a different project directly in one command we can use . cd ../third-folder . I think of this as ‘going to third-folder, which is in the folder above the current one’ . Going Further . ls and cd should get you far enough to run Python scripts (also using python as a command!). . Making your own or finding a terminal commands cheatsheet online can be extremely helpful when first starting out. Repetition is key to becoming comfortable with and memorizing these things. Nobody memorizes them after the first use! .",
            "url": "https://tech.gerardbentley.com/habits/beginner/2020/04/03/terminal.html",
            "relUrl": "/habits/beginner/2020/04/03/terminal.html",
            "date": " • Apr 3, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I’m a software developer interested in web-based apps, ethical / explainable AI, and bringing coding to others. . I started programming at Hotchkiss, back in 2013. I took the one and only Java class then left off until college. . I graduated from Pomona College in 2019 with a BA in Computer Science, then stuck around for the summer and fall as part of a post-bacc research year. Working with professor Joe Osborn we authored “The Videogame Affordances Corpus” at EXAG 2019, which was the first paper for our ‘Formal Analysis of Interactive Media (FAIM) Lab’. My work over that year focused mainly on testing Pytorch models to analyze in-game screenshots from a collection of classic action and adventure games. . Through the pandemic I took a contract role for an Edu-tech startup Edlyft (started by some fellow Hotchkiss alums!) . In January of 2021 I started a job with Cascade Financial Services doing Python automation and working on some legacy projects. . The only machine learning I work on there focuses on mortgage returns and already has established models and usecases. So I started part-time teaching AI and Python topics with AI Camp to get back to education and ML. .",
          "url": "https://tech.gerardbentley.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://tech.gerardbentley.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}